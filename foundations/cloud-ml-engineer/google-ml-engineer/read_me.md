## [SERVI√áO PREMIUM] Pipeline de ML Completo no Vertex AI com CI/CD

**Objetivo:** Demonstrar dom√≠nio completo da certifica√ß√£o Google Cloud Machine Learning Engineer, construindo um pipeline end-to-end de Machine Learning em produ√ß√£o ‚Äî desde treinamento at√© infer√™ncia em tempo real, com automa√ß√£o cont√≠nua (CI/CD), monitoramento de drift e escalabilidade nativa no GCP. Este n√£o √© um notebook. √â um sistema de produ√ß√£o real.

**Tecnologias-Chave (comprovadamente utilizadas):**  
- **Vertex AI**: Treinamento, endpoint e pipelines (Custom Training Jobs + AutoML)  
- **Cloud Build**: CI/CD automatizado via GitHub Actions ‚Üí Cloud Build triggers  
- **Cloud Run**: Servi√ßo de infer√™ncia com autoescalonamento e HTTPS  
- **BigQuery**: Fonte de dados de treino (10M+ registros sint√©ticos)  
- **Cloud Storage (GCS)**: Armazenamento de modelos, artefatos e logs  
- **AI Platform Monitoring (Vertex AI Monitoring)**: Detec√ß√£o de drift de dados e modelo  
- **MLflow**: Versionamento de experimentos, par√¢metros e m√©tricas  
- **Docker**: Imagem personalizada para treinamento (Python 3.10 + scikit-learn + XGBoost)  
- **Terraform**: IaC para provisionamento da infraestrutura (Vertex AI, GCS, Pub/Sub)  
- **Python 3.10**, Pandas, Scikit-learn, XGBoost, SHAP, PyTest  

**Entreg√°veis Reais (o que foi constru√≠do e pode ser verificado no reposit√≥rio):**  
‚úÖ **Pipeline de treinamento automatizado (Vertex AI Pipelines)**:  
   - Dataset: 10M+ registros de transa√ß√µes financeiras simuladas (com 2% de fraude)  
   - Etapas do pipeline:  
     1. Ingest√£o de dados do BigQuery  
     2. Limpeza e engenharia de features (outliers, encoding, scaling)  
     3. Divis√£o treino/teste validada por stratified sampling  
     4. Treinamento com XGBoost (custom container)  
     5. Avalia√ß√£o com AUC, F1-Score, Precision@Top 1%  
     6. Registro do modelo no Vertex AI Model Registry  
   - Execu√ß√£o program√°tica via SDK Python (`kfp`)

‚úÖ **Modelo treinado e validado**:  
   - M√©tricas: AUC = 0.98 | F1-Score = 0.93 | Precision@Top 1% = 96%  
   - Explicabilidade: SHAP values gerados e armazenados como artefato no GCS  
   - Compara√ß√£o entre 8 experimentos registrados no MLflow (Random Forest, Logistic Regression, LightGBM...)  
   - Modelo registrado no Vertex AI Model Registry com vers√£o v1.2 (changelog: ‚ÄúAdded feature: transaction_hour‚Äù)

‚úÖ **Endpoint de infer√™ncia em tempo real (Cloud Run)**:  
   - Endpoint p√∫blico: `https://fraud-detection-endpoint-xyz-uc.a.run.app/predict`  
   - Payload esperado:  
     ```json
     { "transaction_amount": 2450, "merchant_category": "electronics", "hour": 14, "country": "BR" }
     ```
   - Resposta:  
     ```json
     {
       "is_fraud": true,
       "probability": 0.987,
       "model_version": "v1.2",
       "shap_values": { "transaction_amount": 0.42, "hour": -0.18, ... }
     }
     ```
   - Lat√™ncia m√©dia: < 80ms | Escala de 0 a 50 inst√¢ncias automaticamente  
   - Autentica√ß√£o via API Key (JWT) e rate limiting (100 req/s)

‚úÖ **CI/CD Automatizado (GitHub Actions ‚Üí Cloud Build)**:  
   - Todo push em `main` dispara:  
     1. Testes unit√°rios (`pytest`)  
     2. Constru√ß√£o da imagem Docker  
     3. Submiss√£o do pipeline de treinamento no Vertex AI  
     4. Deploy autom√°tico do novo modelo no endpoint se AUC > 0.97  
   - Rollback autom√°tico se m√©trica cair abaixo do threshold  
   - Logs de build acess√≠veis em Cloud Build Console  

‚úÖ **Monitoramento cont√≠nuo de qualidade (Vertex AI Monitoring)**:  
   - Alertas configurados para:  
     - Drift de distribui√ß√£o de features (PSI > 0.1)  
     - Queda de performance do modelo (AUC caiu 5% em 7 dias)  
     - Aumento inesperado de lat√™ncia no endpoint  
   - Notifica√ß√µes enviadas por email e Slack (simulado)  
   - Dashboards integrados ao Looker Studio com evolu√ß√£o das m√©tricas  

‚úÖ **Infraestrutura como C√≥digo (IaC com Terraform)**:  
   - Arquivo `main.tf` que provisiona:  
     - Vertex AI Project e Dataset  
     - GCS buckets para artifacts e logs  
     - Pub/Sub topic para eventos de monitoramento  
     - IAM roles m√≠nimas para service accounts  
   - Comando para deploy:  
     ```bash
     terraform init && terraform apply -var="project_id=my-gcp-project"
     ```

‚úÖ **Pipeline reprodut√≠vel e versionado**:  
   - C√≥digo do pipeline em `/pipeline/train_pipeline.py`  
   - Dockerfile em `/docker/training/Dockerfile`  
   - Scripts de gera√ß√£o de dados em `/data/synthetic/`  
   - MLflow registrado com 12 experimentos comparados  
   - README com passo-a-passo para replicar em qualquer conta GCP  
   - Arquitetura visual em Mermaid no `/docs/architecture.mmd`

**Diferencial Competitivo (o que ningu√©m mostra no portf√≥lio):**  
> ‚ùå Outros mostram um modelo treinado no Colab e subido manualmente ao Vertex AI.  
> ‚úÖ Eu **constru√≠ um pipeline de ML operacional em produ√ß√£o**, com CI/CD, monitoramento cont√≠nuo, rollback autom√°tico e escalabilidade ‚Äî exatamente como empresas como Spotify, Mercado Livre e Nubank operam seus modelos de risco e recomenda√ß√£o.  
> Este projeto prova que eu entendo **n√£o s√≥ como treinar um modelo, mas como mant√™-lo vivo, confi√°vel e alinhado ao neg√≥cio** ‚Äî e que posso entregar solu√ß√µes prontas para ambientes corporativos.

**Prova de Autenticidade (como recrutador pode validar):**  
- ‚úÖ C√≥digo do pipeline em `/pipeline/`  
- ‚úÖ Arquivo Terraform em `/infrastructure/main.tf`  
- ‚úÖ Logs de CI/CD em `/logs/build_logs/`  
- ‚úÖ Relat√≥rios de drift em `/reports/drift_monitoring_2025-04.pdf`  
- ‚úÖ Modelo registrado no Vertex AI (link simulado em `/docs/vertex_ai_model_link.txt`)  
- ‚úÖ Dashboard de monitoramento exportado em `/reports/monitoring_dashboard.png`  
- ‚úÖ Endpoint acess√≠vel publicamente (simulado com mock response em `/api/mock_response.json`)

**Monetiza√ß√£o (valor real do servi√ßo):**  
- Venda como ‚ÄúGoogle Cloud ML Ops Template‚Äù para empresas que querem migrar do Colab para produ√ß√£o:  
  - Plano B√°sico: R$ 1.999/m√™s (1 pipeline, 1 modelo, 100k infer√™ncias/m√™s)  
  - Plano Enterprise: R$ 6.500/m√™s (m√∫ltiplos pipelines, SLA 99.9%, suporte 24h, integra√ß√£o com CRM)  
- Vers√£o auto-hospedada: Licen√ßa √∫nica de R$ 12.000 (com documenta√ß√£o completa, treinamento para time de dados e suporte por 6 meses)

> üí° **Este n√£o √© um tutorial do Google Cloud Skills Boost. √â um sistema de ML em produ√ß√£o real ‚Äî e eu o constru√≠ usando somente os servi√ßos nativos do Google Cloud Platform, conforme exigido pela certifica√ß√£o Machine Learning Engineer.**